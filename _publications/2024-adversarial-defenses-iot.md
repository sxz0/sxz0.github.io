---
title: "Adversarial attacks and defenses on ML-and hardware-based IoT device fingerprinting and identification"
collection: publications
category: manuscripts
permalink: /publication/2024-adversarial-defenses-iot
excerpt: 'Analyzes adversarial robustness of ML and hardware-based fingerprinting methods for IoT device authentication.'
date: 2024-02-01
venue: 'Future Generation Computer Systems, 152, 30–42'
paperurl: 'https://dx.doi.org/10.1016/j.future.2023.10.011'
citation: 'Sánchez Sánchez, Pedro Miguel et al. (2024). "Adversarial attacks and defenses on ML-and hardware-based IoT device fingerprinting and identification." <i>Future Generation Computer Systems</i>, 152, 30–42.'
---

In the last years, the number of IoT devices deployed has suffered an undoubted explosion, reaching the scale of billions. However, some new cybersecurity issues have appeared together with this development. Some of these issues are the deployment of unauthorized devices, malicious code modification, malware deployment, or vulnerability exploitation. This fact has motivated the requirement for new device identification mechanisms based on behavior monitoring. Besides, these solutions have recently leveraged Machine and Deep Learning (ML/DL) techniques due to the advances in this field and the increase in processing capabilities. In contrast, attackers do not stay stalled and have developed adversarial attacks focused on context modification and ML/DL evaluation evasion applied to IoT device identification solutions. However, literature has not yet analyzed in detail the impact of these attacks on individual identification solutions and their countermeasures. This work explores the performance of hardware behavior-based individual device identification, how it is affected by possible context- and ML/DL-focused attacks, and how its resilience can be improved using defense techniques. In this sense, it proposes an LSTM-CNN architecture based on hardware performance behavior for individual device identification. Then, the most usual ML/DL classification techniques have been compared with the proposed architecture using a hardware performance dataset collected from 45 Raspberry Pi devices running identical software. The LSTM-CNN improves previous solutions achieving a ＋0.96 average F1-Score and 0.8 minimum TPR for all devices. Afterward, context- and ML/DL-focused adversarial attacks were applied against the previous model to test its robustness. A temperature-based context attack was not able to disrupt the identification, but some ML/DL state-of-the-art evasion attacks were successful. Finally, adversarial training and model distillation defense techniques are selected to improve the model resilience to evasion attacks, improving its robustness from up to 0.88 attack success ratio to 0.17 in the worst attack case, without degrading its performance in an impactful manner.
